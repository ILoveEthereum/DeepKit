// SPDX-FileCopyrightText: 2024 LiveKit, Inc.\n//\n// SPDX-License-Identifier: Apache-2.0\n\nimport {\n  type JobContext,\n  WorkerOptions,\n  cli,\n  defineAgent,\n  llm,\n  stt,\n  tts,\n  vad,\n  AgentState,\n} from '@livekit/agents';\nimport * as openai from '@livekit/agents-plugin-openai';\nimport * as deepgram from '@livekit/agents-plugin-deepgram';\nimport * as elevenlabs from '@livekit/agents-plugin-elevenlabs';\nimport * as silero from '@livekit/agents-plugin-silero';\nimport { z } from 'zod';\n\nexport default defineAgent({\n  entry: async (ctx: JobContext) => {\n    await ctx.connect();\n\n    console.log('ğŸ¤– Conversational Agent: Waiting for participant to join...');\n    const participant = await ctx.waitForParticipant();\n    console.log(`ğŸ¯ Starting conversational agent for participant: ${participant.identity}`);\n\n    // Initialize Voice Activity Detection (VAD)\n    const vadModel = new silero.VAD({\n      minSpeechDuration: 0.1,\n      minSilenceDuration: 0.5,\n    });\n\n    // Initialize Speech-to-Text\n    let sttModel: stt.STT;\n    if (process.env.DEEPGRAM_API_KEY) {\n      sttModel = new deepgram.STT({\n        model: 'nova-2',\n        language: 'en',\n        smartFormat: true,\n        punctuate: true,\n      });\n    } else {\n      // Fallback to OpenAI Whisper\n      sttModel = new openai.STT({\n        model: 'whisper-1',\n      });\n    }\n\n    // Initialize Text-to-Speech\n    let ttsModel: tts.TTS;\n    if (process.env.ELEVENLABS_API_KEY) {\n      ttsModel = new elevenlabs.TTS({\n        model: 'eleven_turbo_v2_5',\n        voice: 'Rachel', // You can change this to other voices\n      });\n    } else {\n      // Fallback to OpenAI TTS\n      ttsModel = new openai.TTS({\n        model: 'tts-1',\n        voice: 'alloy',\n      });\n    }\n\n    // Initialize Large Language Model\n    const llmModel = new openai.LLM({\n      model: 'gpt-4o-mini',\n      temperature: 0.7,\n    });\n\n    // Define function context for the agent\n    const functionContext: llm.FunctionContext = {\n      getCurrentTime: {\n        description: 'Get the current date and time',\n        parameters: z.object({}),\n        execute: async () => {\n          const now = new Date();\n          return `The current date and time is: ${now.toLocaleString()}`;\n        },\n      },\n      getWeather: {\n        description: 'Get weather information for a specific location',\n        parameters: z.object({\n          location: z.string().describe('The location to get weather for (e.g., \"San Francisco, CA\")'),\n        }),\n        execute: async ({ location }) => {\n          console.log(`ğŸŒ¤ï¸ Getting weather for: ${location}`);\n          try {\n            const response = await fetch(`https://wttr.in/${encodeURIComponent(location)}?format=%C+%t+%h+%w`);\n            if (!response.ok) {\n              throw new Error(`Weather API returned status: ${response.status}`);\n            }\n            const weather = await response.text();\n            return `The weather in ${location} is: ${weather.trim()}`;\n          } catch (error) {\n            console.error('Weather API error:', error);\n            return `I'm sorry, I couldn't retrieve the weather information for ${location} right now.`;\n          }\n        },\n      },\n      calculateMath: {\n        description: 'Perform basic mathematical calculations',\n        parameters: z.object({\n          expression: z.string().describe('Mathematical expression to evaluate (e.g., \"2 + 2\", \"sqrt(16)\")'),\n        }),\n        execute: async ({ expression }) => {\n          console.log(`ğŸ§® Calculating: ${expression}`);\n          try {\n            // Simple safe evaluation for basic math\n            const sanitizedExpression = expression.replace(/[^0-9+\\-*/()\\s\\.]/g, '');\n            const result = eval(sanitizedExpression);\n            return `The result of ${expression} is ${result}`;\n          } catch (error) {\n            return `I couldn't calculate that expression. Please provide a simpler mathematical expression.`;\n          }\n        },\n      },\n    };\n\n    // Create the voice assistant with pipeline\n    const assistant = new llm.VoiceAssistant({\n      vad: vadModel,\n      stt: sttModel,\n      llm: llmModel,\n      tts: ttsModel,\n      chatCtx: {\n        messages: [\n          {\n            role: 'system',\n            content: `You are a helpful and friendly voice assistant. You can:\n            - Have natural conversations\n            - Get current date and time\n            - Provide weather information for any location\n            - Perform basic mathematical calculations\n            \n            Keep your responses conversational and concise since this is a voice interaction. \n            Always be helpful and friendly. If you need to use a function, explain what you're doing.`,\n          },\n        ],\n      },\n      fnctx: functionContext,\n      allowInterruptions: true,\n      minEndpointing: 0.5,\n    });\n\n    // Start the voice assistant\n    assistant.start(ctx.room, participant);\n\n    console.log('ğŸ™ï¸ Voice assistant started! The agent is now ready to interact.');\n    console.log('ğŸ’¡ Available functions:');\n    console.log('   - Get current time');\n    console.log('   - Get weather information');\n    console.log('   - Perform mathematical calculations');\n\n    // Handle participant disconnection\n    participant.on('disconnected', () => {\n      console.log(`ğŸ‘‹ Participant ${participant.identity} disconnected`);\n      assistant.aclose();\n    });\n\n    // Wait for the session to end\n    await assistant.aclose();\n    console.log('ğŸ Voice assistant session ended');\n  },\n});\n\n// CLI setup for running the agent\nif (import.meta.url === `file://${process.argv[1]}`) {\n  cli.runApp(\n    new WorkerOptions({\n      agent: (await import('./agent.js')).default,\n      wsURL: process.env.LIVEKIT_URL,\n      apiKey: process.env.LIVEKIT_API_KEY,\n      apiSecret: process.env.LIVEKIT_API_SECRET,\n    })\n  );\n}\n
