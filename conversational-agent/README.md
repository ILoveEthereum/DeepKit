# ü§ñ LiveKit Conversational Agent\n\nA real-time conversational AI agent built with the [LiveKit Agents framework](https://github.com/livekit/agents-js). This agent provides natural voice conversations with function calling capabilities including weather information, time queries, and mathematical calculations.\n\n## ‚ú® Features\n\n- **Real-time Voice Conversation**: Natural speech-to-speech interaction\n- **Voice Activity Detection (VAD)**: Automatic speech detection using Silero VAD\n- **Multi-provider Support**: \n  - **STT**: Deepgram (primary) or OpenAI Whisper (fallback)\n  - **TTS**: ElevenLabs (primary) or OpenAI TTS (fallback)\n  - **LLM**: OpenAI GPT-4o-mini\n- **Function Calling**: Built-in capabilities for:\n  - Current date and time\n  - Weather information for any location\n  - Mathematical calculations\n- **Interruption Handling**: Natural conversation flow with interruption support\n- **Production Ready**: Built on LiveKit's battle-tested infrastructure\n\n## üöÄ Quick Start\n\n### Prerequisites\n\n1. **LiveKit Server**: You need access to a LiveKit server instance\n   - [LiveKit Cloud](https://livekit.io/cloud) (recommended for quick start)\n   - [Self-hosted LiveKit server](https://docs.livekit.io/home/self-hosting/deployment)\n\n2. **API Keys**: At minimum, you need:\n   - OpenAI API key (for LLM and fallback STT/TTS)\n   - LiveKit API credentials\n\n### Installation\n\n1. **Clone and setup the project**:\n   ```bash\n   git clone <your-repo-url>\n   cd conversational-agent\n   npm install\n   ```\n\n2. **Configure environment variables**:\n   ```bash\n   cp .env.example .env\n   ```\n   \n   Edit `.env` with your credentials:\n   ```env\n   # Required: LiveKit Configuration\n   LIVEKIT_URL=wss://your-livekit-server.livekit.cloud\n   LIVEKIT_API_KEY=your-livekit-api-key\n   LIVEKIT_API_SECRET=your-livekit-api-secret\n   \n   # Required: OpenAI for LLM\n   OPENAI_API_KEY=your-openai-api-key\n   \n   # Optional: Enhanced providers\n   DEEPGRAM_API_KEY=your-deepgram-api-key\n   ELEVENLABS_API_KEY=your-elevenlabs-api-key\n   ```\n\n3. **Build the project**:\n   ```bash\n   npm run build\n   ```\n\n### Running the Agent\n\n1. **Start the agent worker**:\n   ```bash\n   npm run dev\n   ```\n   \n   The agent will start and wait for room connections.\n\n2. **Test with the web client**:\n   - Open `client.html` in your browser\n   - Enter your LiveKit server URL and access token\n   - Click \"Connect to Agent\" and start talking!\n\n## üõ†Ô∏è Environment Variables\n\n### Required Variables\n\n| Variable | Description | Example |\n|----------|-------------|----------|\n| `LIVEKIT_URL` | Your LiveKit server WebSocket URL | `wss://myproject.livekit.cloud` |\n| `LIVEKIT_API_KEY` | LiveKit API key | `APIxxxxxxxxxxxxx` |\n| `LIVEKIT_API_SECRET` | LiveKit API secret | `xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx` |\n| `OPENAI_API_KEY` | OpenAI API key for LLM and fallback services | `sk-xxxxxxxxxxxxxxxxxxxxxxx` |\n\n### Optional Variables (Enhanced Features)\n\n| Variable | Description | Default Fallback |\n|----------|-------------|------------------|\n| `DEEPGRAM_API_KEY` | Deepgram for enhanced STT | OpenAI Whisper |\n| `ELEVENLABS_API_KEY` | ElevenLabs for enhanced TTS | OpenAI TTS |\n| `AZURE_OPENAI_ENDPOINT` | Azure OpenAI endpoint | Standard OpenAI |\n| `AZURE_OPENAI_API_KEY` | Azure OpenAI API key | Standard OpenAI |\n| `AZURE_OPENAI_DEPLOYMENT` | Azure OpenAI deployment name | Standard OpenAI |\n\n## üéØ Usage Examples\n\n### Basic Conversation\n```\nUser: \"Hello, how are you?\"\nAgent: \"Hello! I'm doing great, thank you for asking! I'm here to help you with any questions or tasks you might have. How can I assist you today?\"\n```\n\n### Function Calling Examples\n\n1. **Time Queries**:\n   ```\n   User: \"What time is it?\"\n   Agent: \"The current date and time is: January 25, 2025, 2:30:45 PM PST\"\n   ```\n\n2. **Weather Information**:\n   ```\n   User: \"What's the weather like in San Francisco?\"\n   Agent: \"Let me check the weather for San Francisco... The weather in San Francisco is: Clear 62¬∞F 45% NW 8mph\"\n   ```\n\n3. **Mathematical Calculations**:\n   ```\n   User: \"What's 15 times 7?\"\n   Agent: \"Let me calculate that for you... The result of 15 * 7 is 105\"\n   ```\n\n## üèóÔ∏è Architecture\n\n### Core Components\n\n1. **Voice Activity Detection (VAD)**: \n   - Uses Silero VAD for accurate speech detection\n   - Configurable speech/silence thresholds\n\n2. **Speech-to-Text (STT)**:\n   - Primary: Deepgram Nova-2 model\n   - Fallback: OpenAI Whisper\n\n3. **Large Language Model (LLM)**:\n   - OpenAI GPT-4o-mini with function calling\n   - Conversation memory and context management\n\n4. **Text-to-Speech (TTS)**:\n   - Primary: ElevenLabs Turbo v2.5\n   - Fallback: OpenAI TTS\n\n5. **Function Registry**:\n   - Extensible function calling system\n   - Built-in functions for time, weather, and math\n\n### Data Flow\n\n```\nUser Speech ‚Üí VAD ‚Üí STT ‚Üí LLM (+ Functions) ‚Üí TTS ‚Üí Agent Speech\n                ‚Üì\n           Real-time audio streaming via LiveKit\n```\n\n## üîß Development\n\n### Project Structure\n\n```\nconversational-agent/\n‚îú‚îÄ‚îÄ agent.ts              # Main agent implementation\n‚îú‚îÄ‚îÄ client.html           # Test web client\n‚îú‚îÄ‚îÄ package.json          # Node.js dependencies\n‚îú‚îÄ‚îÄ tsconfig.json         # TypeScript configuration\n‚îú‚îÄ‚îÄ .env.example          # Environment template\n‚îú‚îÄ‚îÄ .gitignore           # Git ignore rules\n‚îî‚îÄ‚îÄ README.md            # This file\n```\n\n### Scripts\n\n| Command | Description |\n|---------|-------------|\n| `npm run build` | Compile TypeScript to JavaScript |\n| `npm run dev` | Run agent in development mode |\n| `npm run start` | Run compiled agent |\n| `npm run connect` | Connect agent to specific room |\n\n### Adding Custom Functions\n\nTo add new functions to the agent, edit the `functionContext` in `agent.ts`:\n\n```typescript\nconst functionContext: llm.FunctionContext = {\n  // Existing functions...\n  \n  myCustomFunction: {\n    description: 'Description of what this function does',\n    parameters: z.object({\n      param1: z.string().describe('Parameter description'),\n    }),\n    execute: async ({ param1 }) => {\n      // Your function logic here\n      return `Result: ${param1}`;\n    },\n  },\n};\n```\n\n## üö¢ Deployment\n\n### Production Deployment\n\n1. **Build the project**:\n   ```bash\n   npm run build\n   ```\n\n2. **Set production environment variables**:\n   - Use a secure method to set environment variables\n   - Never commit `.env` files to version control\n\n3. **Run with process manager**:\n   ```bash\n   # Using PM2\n   pm2 start dist/agent.js --name \"conversational-agent\"\n   \n   # Using Docker\n   docker build -t conversational-agent .\n   docker run -d --env-file .env conversational-agent\n   ```\n\n### Scaling\n\n- Multiple agent workers can run simultaneously\n- LiveKit automatically load balances between workers\n- Each worker can handle multiple concurrent agent sessions\n\n## üîí Security Best Practices\n\n- ‚úÖ Environment variables for all sensitive data\n- ‚úÖ Comprehensive `.gitignore` to prevent credential leaks\n- ‚úÖ Input validation on all function parameters\n- ‚úÖ Safe mathematical expression evaluation\n- ‚úÖ Error handling without exposing sensitive information\n\n## üêõ Troubleshooting\n\n### Common Issues\n\n1. **\"Agent not connecting\"**:\n   - Verify `LIVEKIT_URL`, `LIVEKIT_API_KEY`, and `LIVEKIT_API_SECRET`\n   - Check LiveKit server status\n   - Ensure WebSocket connectivity\n\n2. **\"No audio from agent\"**:\n   - Verify TTS provider API keys\n   - Check audio permissions in browser\n   - Test with different TTS providers\n\n3. **\"Speech recognition not working\"**:\n   - Verify STT provider API keys\n   - Check microphone permissions\n   - Test with different STT providers\n\n4. **\"Function calls failing\"**:\n   - Check function parameter validation\n   - Verify external API connectivity (weather, etc.)\n   - Review function execution logs\n\n### Debug Mode\n\nRun with debug logging:\n```bash\nDEBUG=livekit* npm run dev\n```\n\n## ü§ù Contributing\n\n1. Fork the repository\n2. Create a feature branch\n3. Make your changes\n4. Add tests if applicable\n5. Submit a pull request\n\n## üìÑ License\n\nThis project is licensed under the Apache License 2.0. See the [LICENSE](LICENSE) file for details.\n\n## üîó Resources\n\n- [LiveKit Documentation](https://docs.livekit.io/)\n- [LiveKit Agents Framework](https://github.com/livekit/agents-js)\n- [OpenAI API Documentation](https://platform.openai.com/docs)\n- [Deepgram API Documentation](https://developers.deepgram.com/)\n- [ElevenLabs API Documentation](https://elevenlabs.io/docs)\n\n---\n\n**Built with ‚ù§Ô∏è using LiveKit Agents**\n
